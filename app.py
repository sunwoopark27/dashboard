import streamlit as st
import os
import tempfile
import fitz  # PyMuPDF
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# OpenAI API í‚¤ ì„¤ì •
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY", "")

# ë²¡í„° ì €ì¥ì†Œ ë””ë ‰í† ë¦¬ ì„¤ì •
VECTOR_STORE_DIR = "vectorstore"

def extract_text_from_pdf(pdf_file):
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as temp_file:
        temp_file.write(pdf_file.getvalue())
        temp_file_path = temp_file.name

    doc = fitz.open(temp_file_path)
    text = ""
    for page in doc:
        text += page.get_text("text") + "\n"

    # ì„ì‹œ íŒŒì¼ ì‚­ì œ
    os.unlink(temp_file_path)
    return text

def create_vectorstore(text, embeddings):
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=100,
        separators=["\n\n", "\n", ".", " ", ""]
    )
    documents = text_splitter.create_documents([text])

    # ì²­í¬ ìˆ˜ ë°˜í™˜
    return FAISS.from_documents(documents, embeddings), len(documents)

st.set_page_config(page_title="ğŸ“š PDF RAG ì‹œìŠ¤í…œ", layout="wide")
st.title("ğŸ“š PDF ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ")


with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    user_api_key = st.text_input("OpenAI API í‚¤", value=OPENAI_API_KEY, type="password")
    if user_api_key:
        os.environ["OPENAI_API_KEY"] = user_api_key

    st.markdown("---")
    st.markdown("### ğŸ” ëª¨ë¸ ì„¤ì •")
    model_name = st.selectbox(
        "OpenAI ëª¨ë¸ ì„ íƒ",
        ["gpt-3.5-turbo", "gpt-4", "gpt-4-turbo"],
        index=0
    )
    temperature = st.slider("Temperature", min_value=0.0, max_value=1.0, value=0.3, step=0.1)

    st.markdown("---")
    st.markdown("### ğŸ“Š ì²­í¬ ì„¤ì •")
    chunk_size = st.slider("ì²­í¬ í¬ê¸°", min_value=500, max_value=2000, value=1000, step=100)
    chunk_overlap = st.slider("ì²­í¬ ì˜¤ë²„ë©", min_value=0, max_value=500, value=100, step=50)


tab1, tab2 = st.tabs(["ğŸ“¤ PDF ì—…ë¡œë“œ", "â“ ì§ˆì˜ì‘ë‹µ"])


with tab1:
    st.header("PDF íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”", type="pdf")

    if uploaded_file is not None:
        with st.spinner("PDF íŒŒì¼ ì²˜ë¦¬ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
            # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text = extract_text_from_pdf(uploaded_file)
            st.session_state.pdf_text = text

            # í…ìŠ¤íŠ¸ì˜ ì¼ë¶€ë¶„ ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ
            st.subheader("PDF í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°")
            st.text_area("ì¶”ì¶œëœ í…ìŠ¤íŠ¸", text[:1000] + ("..." if len(text) > 1000 else ""), height=200)


            # ë²¡í„° ì €ì¥ì†Œ ìƒì„±
            if st.button("ë²¡í„° ì €ì¥ì†Œ ìƒì„±", use_container_width=True):
                if not user_api_key:
                    st.error("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    with st.spinner("ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì¤‘... ì´ ì‘ì—…ì€ ëª‡ ë¶„ ì •ë„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."):
                        try:
                            embeddings = OpenAIEmbeddings()

                            # ì‚¬ìš©ì ì •ì˜ ì²­í¬ ì„¤ì • ì ìš©
                            text_splitter = RecursiveCharacterTextSplitter(
                                chunk_size=chunk_size,
                                chunk_overlap=chunk_overlap
                            )
                            documents = text_splitter.create_documents([text])

                            # ë²¡í„° ì €ì¥ì†Œ ìƒì„±
                            vectorstore = FAISS.from_documents(documents, embeddings)

                            # ì„¸ì…˜ì— ì €ì¥
                            st.session_state.vectorstore = vectorstore
                            st.session_state.document_chunks = len(documents)

                            # ì„±ê³µ ë©”ì‹œì§€
                            st.success(f"âœ… ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì™„ë£Œ! {len(documents)}ê°œì˜ ì²­í¬ë¡œ ë¶„í• ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            st.info("ì´ì œ 'ì§ˆì˜ì‘ë‹µ' íƒ­ì—ì„œ ì§ˆë¬¸ì„ í•´ë³´ì„¸ìš”!")
                        except Exception as e:
                            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

with tab2:
    st.header("PDF ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ")

    # ë²¡í„° ì €ì¥ì†Œê°€ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
    if 'vectorstore' not in st.session_state:
        st.warning("ë¨¼ì € 'PDF ì—…ë¡œë“œ' íƒ­ì—ì„œ PDFë¥¼ ì—…ë¡œë“œí•˜ê³  ë²¡í„° ì €ì¥ì†Œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
    else:
        st.success(f"âœ… {st.session_state.get('document_chunks', 0)}ê°œì˜ ì²­í¬ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # ì§ˆë¬¸ ì…ë ¥
        query = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ì´ ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì€ ë¬´ì—‡ì¸ê°€ìš”?")


        if query:
            # ì‚¬ìš©ìê°€ ì…ë ¥í•œ API í‚¤ í™•ì¸
            if not user_api_key:
                st.error("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                    try:
                        # LLM ë° ê²€ìƒ‰ ì²´ì¸ ì„¤ì •
                        llm = ChatOpenAI(
                            model_name=model_name,
                            temperature=temperature
                        )

                        # ê²€ìƒ‰ê¸° ì„¤ì •
                        retriever = st.session_state.vectorstore.as_retriever(
                            search_type="similarity",
                            search_kwargs={"k": 3}
                        )

                        # QA ì²´ì¸ ìƒì„±
                        qa_chain = RetrievalQA.from_chain_type(
                            llm=llm,
                            chain_type="stuff",
                            retriever=retriever,
                            return_source_documents=True
                        )

                        # ì§ˆì˜ì‘ë‹µ ì‹¤í–‰
                        result = qa_chain({"query": query})

                        # ê²°ê³¼ í‘œì‹œ
                        st.subheader("ğŸ“ ë‹µë³€")
                        st.write(result["result"])

                        # ì°¸ì¡° ë¬¸ì„œ í‘œì‹œ
                        with st.expander("ğŸ“š ì°¸ì¡°ëœ ë¬¸ì„œ ì²­í¬"):
                            for i, doc in enumerate(result["source_documents"]):
                                st.markdown(f"**ì²­í¬ {i+1}**")
                                st.text(doc.page_content)
                                st.markdown("---")

                    except Exception as e:
                        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

# í‘¸í„°
st.markdown("---")
st.caption("ë©‹ìŸì´ ì‚¬ìì²˜ëŸ¼")

